{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8697b904",
   "metadata": {},
   "source": [
    "# Практическая работа: Ансамблевые методы - Bagging и Boosting\n",
    "\n",
    "\n",
    "## Цели практической работы\n",
    "\n",
    "В этой практической работе вы:\n",
    "1. Реализуете различные ансамблевые методы\n",
    "2. Сравните их производительность на реальных данных\n",
    "3. Изучите влияние гиперпараметров\n",
    "4. Проанализируете важность признаков\n",
    "5. Примените полученные знания к новому датасету\n",
    "\n",
    "## Структура работы\n",
    "\n",
    "1. **Подготовка данных**\n",
    "2. **Реализация Bagging методов**\n",
    "3. **Реализация Boosting методов** \n",
    "4. **Сравнение методов**\n",
    "5. **Настройка гиперпараметров**\n",
    "6. **Анализ важности признаков**\n",
    "7. **Самостоятельное задание**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96bb55a",
   "metadata": {},
   "source": [
    "## Часть 1: Подготовка данных и импорт библиотек\n",
    "\n",
    "Начнем с импорта необходимых библиотек и загрузки данных для экспериментов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт основных библиотек\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_wine, load_breast_cancer, make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, validation_curve\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Настройка визуализации\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✅ Библиотеки успешно импортированы!\")\n",
    "print(f\"Версия NumPy: {np.__version__}\")\n",
    "print(f\"Версия Pandas: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abc8d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт ансамблевых методов\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    BaggingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier\n",
    ")\n",
    "\n",
    "# Попробуем импортировать XGBoost (если установлен)\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGBOOST_AVAILABLE = True\n",
    "    print(\"✅ XGBoost доступен\")\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"⚠️ XGBoost не установлен. Установите командой: pip install xgboost\")\n",
    "\n",
    "print(\"✅ Ансамблевые методы импортированы!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e58ed10",
   "metadata": {},
   "source": [
    "### Задание 1.1: Загрузка и исследование данных\n",
    "\n",
    "Загрузите датасет Wine и изучите его структуру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03e543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Загрузите датасет Wine\n",
    "wine_data = load_wine()\n",
    "X_wine, y_wine = wine_data.data, wine_data.target\n",
    "\n",
    "# TODO: Создайте DataFrame для удобства работы\n",
    "wine_df = pd.DataFrame(X_wine, columns=wine_data.feature_names)\n",
    "wine_df['target'] = y_wine\n",
    "wine_df['target_name'] = [wine_data.target_names[i] for i in y_wine]\n",
    "\n",
    "# TODO: Выведите основную информацию о датасете\n",
    "print(\"Информация о датасете Wine:\")\n",
    "print(f\"Размер: {wine_df.shape}\")\n",
    "print(f\"Признаки: {len(wine_data.feature_names)}\")\n",
    "print(f\"Классы: {wine_data.target_names}\")\n",
    "print(f\"Распределение классов:\\n{wine_df['target_name'].value_counts()}\")\n",
    "\n",
    "# Покажите первые строки\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a0dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация распределения классов\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# TODO: Создайте гистограмму распределения классов\n",
    "wine_df['target_name'].value_counts().plot(kind='bar', ax=axes[0], color='skyblue')\n",
    "axes[0].set_title('Распределение классов в датасете Wine')\n",
    "axes[0].set_xlabel('Класс вина')\n",
    "axes[0].set_ylabel('Количество образцов')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# TODO: Создайте круговую диаграмму\n",
    "wine_df['target_name'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%')\n",
    "axes[1].set_title('Процентное распределение классов')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TODO: Проверьте наличие пропущенных значений\n",
    "print(f\"\\nПропущенные значения: {wine_df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32b4658",
   "metadata": {},
   "source": [
    "### Задание 1.2: Подготовка данных для обучения\n",
    "\n",
    "Разделите данные на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b3edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Разделите данные на признаки и целевую переменную\n",
    "X = wine_df.drop(['target', 'target_name'], axis=1)\n",
    "y = wine_df['target']\n",
    "\n",
    "# TODO: Разделите на обучающую и тестовую выборки (70/30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Размер обучающей выборки: {X_train.shape}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape}\")\n",
    "\n",
    "# TODO: Стандартизируйте данные\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"✅ Данные подготовлены и стандартизированы!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5aa8ae",
   "metadata": {},
   "source": [
    "## Часть 2: Реализация Bagging методов\n",
    "\n",
    "Теперь реализуем и сравним различные Bagging методы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6281b2c1",
   "metadata": {},
   "source": [
    "### Задание 2.1: Сравнение одиночного дерева с Bagging\n",
    "\n",
    "Сравните производительность одиночного дерева решений с Bagging ансамблем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f928888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Создайте одиночное дерево решений\n",
    "single_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# TODO: Создайте Bagging классификатор\n",
    "bagging_clf = BaggingClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(),\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# TODO: Обучите модели\n",
    "single_tree.fit(X_train_scaled, y_train)\n",
    "bagging_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# TODO: Сделайте предсказания\n",
    "single_pred = single_tree.predict(X_test_scaled)\n",
    "bagging_pred = bagging_clf.predict(X_test_scaled)\n",
    "\n",
    "# TODO: Вычислите точность\n",
    "single_accuracy = accuracy_score(y_test, single_pred)\n",
    "bagging_accuracy = accuracy_score(y_test, bagging_pred)\n",
    "\n",
    "print(\"Сравнение производительности:\")\n",
    "print(f\"Одиночное дерево решений: {single_accuracy:.4f}\")\n",
    "print(f\"Bagging (100 деревьев): {bagging_accuracy:.4f}\")\n",
    "print(f\"Улучшение: {bagging_accuracy - single_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2932824",
   "metadata": {},
   "source": [
    "### Задание 2.2: Random Forest и Extra Trees\n",
    "\n",
    "Реализуйте Random Forest и Extra Trees, сравните их производительность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322c1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Создайте Random Forest классификатор\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# TODO: Создайте Extra Trees классификатор\n",
    "et_clf = ExtraTreesClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# TODO: Обучите модели и оцените их с помощью кросс-валидации\n",
    "rf_scores = cross_val_score(rf_clf, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "et_scores = cross_val_score(et_clf, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"Результаты кросс-валидации:\")\n",
    "print(f\"Random Forest: {rf_scores.mean():.4f} ± {rf_scores.std():.4f}\")\n",
    "print(f\"Extra Trees: {et_scores.mean():.4f} ± {et_scores.std():.4f}\")\n",
    "\n",
    "# TODO: Обучите финальные модели\n",
    "rf_clf.fit(X_train_scaled, y_train)\n",
    "et_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# TODO: Сделайте предсказания\n",
    "rf_pred = rf_clf.predict(X_test_scaled)\n",
    "et_pred = et_clf.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nТочность на тестовой выборке:\")\n",
    "print(f\"Random Forest: {accuracy_score(y_test, rf_pred):.4f}\")\n",
    "print(f\"Extra Trees: {accuracy_score(y_test, et_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d858f5ae",
   "metadata": {},
   "source": [
    "### Задание 2.3: Анализ важности признаков в Random Forest\n",
    "\n",
    "Проанализируйте важность признаков и визуализируйте результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883dc3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Получите важность признаков из Random Forest\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_clf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# TODO: Визуализируйте топ-10 наиболее важных признаков\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=feature_importance.head(10), y='feature', x='importance', palette='viridis')\n",
    "plt.title('Топ 10 наиболее важных признаков (Random Forest)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Важность признака', fontsize=12)\n",
    "plt.ylabel('Признак', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TODO: Выведите топ-5 признаков\n",
    "print(\"Топ 5 наиболее важных признаков:\")\n",
    "for i, row in feature_importance.head().iterrows():\n",
    "    print(f\"{row['feature']}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58266df",
   "metadata": {},
   "source": [
    "## Часть 3: Реализация Boosting методов\n",
    "\n",
    "Теперь реализуем различные Boosting алгоритмы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaef6d0",
   "metadata": {},
   "source": [
    "### Задание 3.1: AdaBoost\n",
    "\n",
    "Реализуйте AdaBoost и исследуйте влияние количества деревьев на производительность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c1f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Исследуйте влияние количества оценок на производительность AdaBoost\n",
    "n_estimators_range = [1, 5, 10, 25, 50, 100, 200]\n",
    "ada_train_scores = []\n",
    "ada_test_scores = []\n",
    "\n",
    "for n_est in n_estimators_range:\n",
    "    # TODO: Создайте AdaBoost классификатор\n",
    "    ada_clf = AdaBoostClassifier(\n",
    "        base_estimator=DecisionTreeClassifier(max_depth=1),  # Пни решений\n",
    "        n_estimators=n_est,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # TODO: Обучите модель\n",
    "    ada_clf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # TODO: Получите точность на обучающей и тестовой выборках\n",
    "    train_pred = ada_clf.predict(X_train_scaled)\n",
    "    test_pred = ada_clf.predict(X_test_scaled)\n",
    "    \n",
    "    ada_train_scores.append(accuracy_score(y_train, train_pred))\n",
    "    ada_test_scores.append(accuracy_score(y_test, test_pred))\n",
    "\n",
    "# TODO: Визуализируйте кривые обучения\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_estimators_range, ada_train_scores, 'o-', label='Обучающая выборка', linewidth=2)\n",
    "plt.plot(n_estimators_range, ada_test_scores, 'o-', label='Тестовая выборка', linewidth=2)\n",
    "plt.xlabel('Количество базовых оценок')\n",
    "plt.ylabel('Точность')\n",
    "plt.title('Кривые обучения AdaBoost')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Найдите оптимальное количество деревьев\n",
    "optimal_n = n_estimators_range[np.argmax(ada_test_scores)]\n",
    "best_score = max(ada_test_scores)\n",
    "print(f\"Оптимальное количество деревьев: {optimal_n}\")\n",
    "print(f\"Лучшая точность: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a9cdb5",
   "metadata": {},
   "source": [
    "### Задание 3.2: Gradient Boosting\n",
    "\n",
    "Реализуйте Gradient Boosting и исследуйте влияние learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742fd6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Исследуйте влияние learning_rate на Gradient Boosting\n",
    "learning_rates = [0.01, 0.05, 0.1, 0.2, 0.5, 1.0]\n",
    "gb_results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    # TODO: Создайте Gradient Boosting классификатор\n",
    "    gb_clf = GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=lr,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # TODO: Оцените с помощью кросс-валидации\n",
    "    scores = cross_val_score(gb_clf, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    gb_results.append({\n",
    "        'learning_rate': lr,\n",
    "        'mean_score': scores.mean(),\n",
    "        'std_score': scores.std()\n",
    "    })\n",
    "\n",
    "# TODO: Визуализируйте результаты\n",
    "gb_df = pd.DataFrame(gb_results)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(gb_df['learning_rate'], gb_df['mean_score'], \n",
    "             yerr=gb_df['std_score'], fmt='bo-', linewidth=2, markersize=8, capsize=5)\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Точность (Cross-validation)')\n",
    "plt.title('Влияние Learning Rate на производительность Gradient Boosting')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xscale('log')\n",
    "plt.show()\n",
    "\n",
    "print(\"Результаты для различных Learning Rate:\")\n",
    "for result in gb_results:\n",
    "    print(f\"LR = {result['learning_rate']}: {result['mean_score']:.4f} ± {result['std_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7086224",
   "metadata": {},
   "source": [
    "### Задание 3.3: XGBoost (если доступен)\n",
    "\n",
    "Если XGBoost установлен, протестируйте его производительность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a1fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if XGBOOST_AVAILABLE:\n",
    "    # TODO: Создайте XGBoost классификатор\n",
    "    xgb_clf = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        random_state=42,\n",
    "        eval_metric='mlogloss'  # Подавление предупреждений\n",
    "    )\n",
    "    \n",
    "    # TODO: Оцените производительность\n",
    "    xgb_scores = cross_val_score(xgb_clf, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"XGBoost CV Score: {xgb_scores.mean():.4f} ± {xgb_scores.std():.4f}\")\n",
    "    \n",
    "    # TODO: Обучите финальную модель\n",
    "    xgb_clf.fit(X_train_scaled, y_train)\n",
    "    xgb_pred = xgb_clf.predict(X_test_scaled)\n",
    "    xgb_accuracy = accuracy_score(y_test, xgb_pred)\n",
    "    print(f\"XGBoost Test Accuracy: {xgb_accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"XGBoost не доступен. Установите командой: pip install xgboost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1511ad25",
   "metadata": {},
   "source": [
    "## Часть 4: Комплексное сравнение методов\n",
    "\n",
    "Сравним все реализованные методы на одном датасете."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a264f683",
   "metadata": {},
   "source": [
    "### Задание 4.1: Сравнение всех методов\n",
    "\n",
    "Создайте сравнительную таблицу производительности всех методов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc172369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Создайте словарь с моделями для сравнения\n",
    "models = {\n",
    "    'Single Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Bagging': BaggingClassifier(base_estimator=DecisionTreeClassifier(), \n",
    "                               n_estimators=100, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
    "                                 n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
    "                                                   max_depth=3, random_state=42)\n",
    "}\n",
    "\n",
    "# Добавим XGBoost если доступен\n",
    "if XGBOOST_AVAILABLE:\n",
    "    models['XGBoost'] = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3,\n",
    "                                     random_state=42, eval_metric='mlogloss')\n",
    "\n",
    "# TODO: Оцените все модели\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    print(f\"Обучение {name}...\")\n",
    "    \n",
    "    # Кросс-валидация\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Обучение на полной обучающей выборке\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    test_pred = model.predict(X_test_scaled)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    \n",
    "    # Вычисление AUC для многоклассовой классификации\n",
    "    try:\n",
    "        test_pred_proba = model.predict_proba(X_test_scaled)\n",
    "        auc_score = roc_auc_score(y_test, test_pred_proba, multi_class='ovr')\n",
    "    except:\n",
    "        auc_score = np.nan\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'CV Mean': cv_scores.mean(),\n",
    "        'CV Std': cv_scores.std(),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'AUC Score': auc_score\n",
    "    })\n",
    "\n",
    "# TODO: Создайте DataFrame с результатами\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Test Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"СРАВНЕНИЕ ПРОИЗВОДИТЕЛЬНОСТИ МОДЕЛЕЙ\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False, float_format='%.4f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4abdc3",
   "metadata": {},
   "source": [
    "### Задание 4.2: Визуализация сравнения\n",
    "\n",
    "Создайте визуализации для сравнения производительности моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ba1217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Создайте визуализацию сравнения моделей\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# График 1: Точность кросс-валидации\n",
    "ax1 = axes[0, 0]\n",
    "bars1 = ax1.barh(results_df['Model'], results_df['CV Mean'], color='skyblue')\n",
    "ax1.set_xlabel('CV Accuracy')\n",
    "ax1.set_title('Точность кросс-валидации', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "# Добавим значения на график\n",
    "for i, bar in enumerate(bars1):\n",
    "    width = bar.get_width()\n",
    "    ax1.text(width + 0.001, bar.get_y() + bar.get_height()/2, \n",
    "             f'{width:.3f}', ha='left', va='center', fontsize=9)\n",
    "\n",
    "# График 2: Точность на тестовой выборке\n",
    "ax2 = axes[0, 1]\n",
    "bars2 = ax2.barh(results_df['Model'], results_df['Test Accuracy'], color='lightcoral')\n",
    "ax2.set_xlabel('Test Accuracy')\n",
    "ax2.set_title('Точность на тестовой выборке', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "# Добавим значения на график\n",
    "for i, bar in enumerate(bars2):\n",
    "    width = bar.get_width()\n",
    "    ax2.text(width + 0.001, bar.get_y() + bar.get_height()/2, \n",
    "             f'{width:.3f}', ha='left', va='center', fontsize=9)\n",
    "\n",
    "# График 3: AUC Score (если доступен)\n",
    "ax3 = axes[1, 0]\n",
    "auc_data = results_df.dropna(subset=['AUC Score'])\n",
    "if not auc_data.empty:\n",
    "    bars3 = ax3.barh(auc_data['Model'], auc_data['AUC Score'], color='lightgreen')\n",
    "    ax3.set_xlabel('AUC Score')\n",
    "    ax3.set_title('AUC Score', fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    for i, bar in enumerate(bars3):\n",
    "        width = bar.get_width()\n",
    "        ax3.text(width + 0.001, bar.get_y() + bar.get_height()/2, \n",
    "                 f'{width:.3f}', ha='left', va='center', fontsize=9)\n",
    "else:\n",
    "    ax3.text(0.5, 0.5, 'AUC Score недоступен', ha='center', va='center', transform=ax3.transAxes)\n",
    "\n",
    "# График 4: Сравнение CV и Test точности\n",
    "ax4 = axes[1, 1]\n",
    "x_pos = np.arange(len(results_df))\n",
    "ax4.bar(x_pos - 0.2, results_df['CV Mean'], 0.4, label='CV Accuracy', alpha=0.7)\n",
    "ax4.bar(x_pos + 0.2, results_df['Test Accuracy'], 0.4, label='Test Accuracy', alpha=0.7)\n",
    "ax4.set_xlabel('Модели')\n",
    "ax4.set_ylabel('Точность')\n",
    "ax4.set_title('Сравнение CV и Test точности', fontweight='bold')\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980c74ea",
   "metadata": {},
   "source": [
    "## Часть 5: Настройка гиперпараметров\n",
    "\n",
    "Настроим гиперпараметры для лучшей модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5610ce6",
   "metadata": {},
   "source": [
    "### Задание 5.1: GridSearchCV для Random Forest\n",
    "\n",
    "Используйте GridSearchCV для оптимизации гиперпараметров Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e419ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Определите сетку параметров для Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "print(f\"Общее количество комбинаций: {len(rf_param_grid['n_estimators']) * len(rf_param_grid['max_depth']) * len(rf_param_grid['min_samples_split']) * len(rf_param_grid['min_samples_leaf']) * len(rf_param_grid['max_features'])}\")\n",
    "\n",
    "# Упростим сетку для быстрого выполнения\n",
    "rf_param_grid_simple = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "print(f\"Упрощенная сетка: {len(rf_param_grid_simple['n_estimators']) * len(rf_param_grid_simple['max_depth']) * len(rf_param_grid_simple['min_samples_split']) * len(rf_param_grid_simple['max_features'])} комбинаций\")\n",
    "\n",
    "# TODO: Создайте GridSearchCV\n",
    "rf_grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    rf_param_grid_simple,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # Используем все доступные процессоры\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Запуск Grid Search для Random Forest...\")\n",
    "# TODO: Выполните поиск\n",
    "rf_grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nЛучшие параметры Random Forest:\")\n",
    "print(rf_grid_search.best_params_)\n",
    "print(f\"Лучший CV score: {rf_grid_search.best_score_:.4f}\")\n",
    "\n",
    "# TODO: Оцените оптимизированную модель на тестовой выборке\n",
    "best_rf = rf_grid_search.best_estimator_\n",
    "rf_optimized_pred = best_rf.predict(X_test_scaled)\n",
    "rf_optimized_accuracy = accuracy_score(y_test, rf_optimized_pred)\n",
    "\n",
    "print(f\"Точность оптимизированной модели на тесте: {rf_optimized_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862e2af7",
   "metadata": {},
   "source": [
    "### Задание 5.2: Кривые валидации\n",
    "\n",
    "Постройте кривые валидации для важных гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e895920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Постройте кривые валидации для n_estimators\n",
    "n_estimators_range = np.arange(10, 201, 20)\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    X_train_scaled, y_train,\n",
    "    param_name='n_estimators',\n",
    "    param_range=n_estimators_range,\n",
    "    cv=5, scoring='accuracy', n_jobs=-1\n",
    ")\n",
    "\n",
    "# Вычисление средних и стандартных отклонений\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "train_std = train_scores.std(axis=1)\n",
    "test_mean = test_scores.mean(axis=1)\n",
    "test_std = test_scores.std(axis=1)\n",
    "\n",
    "# TODO: Визуализация кривых валидации\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(n_estimators_range, train_mean, 'o-', color='blue', label='Обучающая выборка')\n",
    "plt.fill_between(n_estimators_range, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
    "\n",
    "plt.plot(n_estimators_range, test_mean, 'o-', color='red', label='Валидационная выборка')\n",
    "plt.fill_between(n_estimators_range, test_mean - test_std, test_mean + test_std, alpha=0.1, color='red')\n",
    "\n",
    "plt.xlabel('Количество деревьев (n_estimators)', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Кривые валидации для Random Forest', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Найти оптимальное количество деревьев\n",
    "optimal_n_estimators = n_estimators_range[np.argmax(test_mean)]\n",
    "print(f\"Оптимальное количество деревьев: {optimal_n_estimators}\")\n",
    "print(f\"Максимальная точность валидации: {test_mean.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55860527",
   "metadata": {},
   "source": [
    "## Часть 6: Самостоятельное задание\n",
    "\n",
    "Теперь примените полученные знания к новому датасету."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5732b566",
   "metadata": {},
   "source": [
    "### Задание 6.1: Работа с датасетом Breast Cancer\n",
    "\n",
    "Загрузите датасет Breast Cancer и повторите анализ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfdc665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Загрузите датасет Breast Cancer\n",
    "cancer_data = load_breast_cancer()\n",
    "X_cancer, y_cancer = cancer_data.data, cancer_data.target\n",
    "\n",
    "# TODO: Создайте DataFrame\n",
    "cancer_df = pd.DataFrame(X_cancer, columns=cancer_data.feature_names)\n",
    "cancer_df['target'] = y_cancer\n",
    "cancer_df['target_name'] = [cancer_data.target_names[i] for i in y_cancer]\n",
    "\n",
    "print(\"Информация о датасете Breast Cancer:\")\n",
    "print(f\"Размер: {cancer_df.shape}\")\n",
    "print(f\"Признаки: {len(cancer_data.feature_names)}\")\n",
    "print(f\"Классы: {cancer_data.target_names}\")\n",
    "print(f\"Распределение классов:\\n{cancer_df['target_name'].value_counts()}\")\n",
    "\n",
    "# TODO: Подготовьте данные\n",
    "X_cancer_clean = cancer_df.drop(['target', 'target_name'], axis=1)\n",
    "y_cancer_clean = cancer_df['target']\n",
    "\n",
    "X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(\n",
    "    X_cancer_clean, y_cancer_clean, test_size=0.3, random_state=42, stratify=y_cancer_clean\n",
    ")\n",
    "\n",
    "# Стандартизация\n",
    "scaler_cancer = StandardScaler()\n",
    "X_train_cancer_scaled = scaler_cancer.fit_transform(X_train_cancer)\n",
    "X_test_cancer_scaled = scaler_cancer.transform(X_test_cancer)\n",
    "\n",
    "print(f\"\\nОбучающая выборка: {X_train_cancer_scaled.shape}\")\n",
    "print(f\"Тестовая выборка: {X_test_cancer_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea28aaf5",
   "metadata": {},
   "source": [
    "### Задание 6.2: Ваш анализ\n",
    "\n",
    "Проведите полный анализ датасета Breast Cancer, включая:\n",
    "1. Сравнение всех ансамблевых методов\n",
    "2. Настройку гиперпараметров для лучшей модели\n",
    "3. Анализ важности признаков\n",
    "4. Выводы и рекомендации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67decb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Ваш код здесь\n",
    "# Подсказка: используйте код из предыдущих заданий как основу\n",
    "\n",
    "print(\"TODO: Реализуйте полный анализ датасета Breast Cancer\")\n",
    "print(\"Включите:\")\n",
    "print(\"1. Сравнение всех ансамблевых методов\")\n",
    "print(\"2. Настройку гиперпараметров\")\n",
    "print(\"3. Визуализации\")\n",
    "print(\"4. Анализ важности признаков\")\n",
    "print(\"5. Выводы\")\n",
    "\n",
    "# Начните с создания словаря моделей\n",
    "models_cancer = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    # Добавьте другие модели\n",
    "}\n",
    "\n",
    "# Ваш анализ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e6f431",
   "metadata": {},
   "source": [
    "## Заключение и выводы\n",
    "\n",
    "### Что мы изучили:\n",
    "\n",
    "1. **Bagging методы:**\n",
    "   - Bootstrap Aggregating снижает дисперсию\n",
    "   - Random Forest добавляет случайность в выбор признаков\n",
    "   - Extra Trees использует случайные разбиения\n",
    "\n",
    "2. **Boosting методы:**\n",
    "   - AdaBoost фокусируется на ошибках предыдущих моделей\n",
    "   - Gradient Boosting оптимизирует функцию потерь\n",
    "   - XGBoost добавляет регуляризацию и оптимизации\n",
    "\n",
    "3. **Практические навыки:**\n",
    "   - Сравнение производительности моделей\n",
    "   - Настройка гиперпараметров с GridSearchCV\n",
    "   - Анализ важности признаков\n",
    "   - Построение кривых обучения и валидации\n",
    "\n",
    "### Ключевые выводы:\n",
    "\n",
    "- Ансамблевые методы почти всегда превосходят одиночные модели\n",
    "- Random Forest - отличный выбор для начала\n",
    "- Boosting методы могут достигать высокой точности, но требуют осторожной настройки\n",
    "- Важность признаков помогает понять данные\n",
    "- Кросс-валидация критически важна для оценки моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d83d6d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
